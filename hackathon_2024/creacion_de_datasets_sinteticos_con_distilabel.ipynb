{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/somosnlp/recursos/blob/main/hackathon_2024/creacion_de_datasets_sinteticos_con_distilabel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agradecimientos\n",
        "\n",
        "Muchas gracias al equipo de Argilla por preparar este notebook de ejemplo, en especial a Daniel Vila Suero (CEO y fundador) y Agustín Piqueres (MLE).\n",
        "\n",
        "Muchas gracias también a Hugging Face por darnos la oportunidad de disfrutar de la PRO API durante el hackathon. Pedimos a todos los equipos responsabilidad, por favor utilizad esta API para el desarrollo de proyectos del hackathon. Así seguiremos pudiendo organizar estos maravillosos eventos gratuitos. ¡Gracias!"
      ],
      "metadata": {
        "id": "lH5SbqdWv3W6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalar requisitos"
      ],
      "metadata": {
        "id": "B86XP2iJvv4_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdY5HkI3eKMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7a3c36-d00f-4b17-e73e-39a8104bf88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.3/254.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -U distilabel[hf-inference-endpoints,argilla] -qqq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distilabel.llm.huggingface.inference_endpoints import InferenceEndpointsLLM\n",
        "from distilabel.tasks import TextGenerationTask\n",
        "from distilabel.tasks import SelfInstructTask\n",
        "from distilabel.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "VujeChEdeSzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import distilabel\n",
        "distilabel.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gKOz0-iKaoHc",
        "outputId": "2fddc989-a35d-46cf-8a75-eefdc7bfb052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introducción\n",
        "\n",
        "En este tutorial se muestra como generar conjuntos de datos sintéticos en Español para entrenar y mejorar modelos del lenguaje en Español.\n",
        "\n",
        "Para ello se utiliza `distilabel` de Argilla, una librería escalable para generar datasets para LLMs.\n",
        "\n",
        "Este cuaderno provee una breve guía de introducción pero se recomienda leer la [documentación](https://distilabel.argilla.io/latest/) y explorar opciones más avanzadas así como casos de uso interesantes, más allá del ejemplo utilizado aquí.\n",
        "\n",
        "En este cuaderno:\n",
        "\n",
        "- Se muestra como generar instrucciones y respuestas para SFT (supervised fine tuning) utilizando Hugging Face Inference for PRO (gracias al sponsorship de Hugging Face).\n",
        "\n",
        "- Se muestra como generar instrucciones y respuestas para SFT (supervised fine tuning) utilizando la GPU de Colab y modelos locales.\n"
      ],
      "metadata": {
        "id": "0D8tHM7Wtgpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generación de instrucciones con HF Inference endpoints\n",
        "\n",
        "Con este apartado, los equipos pueden generar instrucciones en Español sobre distintos temas y para distintas aplicaciones. Aquí se muestra solo un ejemplo muy básico.\n",
        "\n",
        "Para ejecutar este apartado es necesario formar parte de la organización SomosNLP en Hugging Face y configurar el token personal (nivel write) para poder hacer uso de la cuenta PRO.\n",
        "\n",
        "\n",
        "Se ruega no sobrecargar la API de inferencia y hacer pruebas con pequeñas muestras hasta tener claro el caso de uso y en cualquier caso no generar datasets de más de 5000 ejemplos."
      ],
      "metadata": {
        "id": "OOOdMpkfspe2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comprobar acceso a Inference Endpoints"
      ],
      "metadata": {
        "id": "XP95xr4WqVx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "\n",
        "# change endpoint name and namespace once deployed\n",
        "ENDPOINT_NAME = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "\n",
        "\n",
        "llm = InferenceEndpointsLLM(\n",
        "    endpoint_name_or_model_id=ENDPOINT_NAME,\n",
        "    task=TextGenerationTask(),\n",
        "    token=hf_token,\n",
        "    prompt_format=\"llama2\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oHD3ETGewPV",
        "outputId": "25e58241-a2b2-4acd-b4f9-b3e304c98ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distilabel:Using Serverless Inference Endpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.generate([{\"input\": \"Generate a random joke in Spanish, just the joke, no greetings\"}])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMSg8K3Zexop",
        "outputId": "794b139f-2ab9-4099-ecce-aaee2098e3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
              "   'prompt_used': \"<s>[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<</SYS>>\\n\\nGenerate a random joke in Spanish, just the joke, no greetings [/INST]\",\n",
              "   'raw_output': ' ¿Por qué el pollo siempre cruza la calle?\\nPorque quiere llegar al otro lado y decir: \"¡Adivinen quién acaba de cruzar la calle!\" (Why does the chicken always cross the road? Because it wants to get to the other side and say: \"Guess who just crossed the road!\")',\n",
              "   'parsed_output': {'generations': ' ¿Por qué el pollo siempre cruza la calle?\\nPorque quiere llegar al otro lado y decir: \"¡Adivinen quién acaba de cruzar la calle!\" (Why does the chicken always cross the road? Because it wants to get to the other side and say: \"Guess who just crossed the road!\")'}}]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generar dataset de instrucciones por temas\n",
        "\n",
        "Esto es solo un ejemplo y configurando la lista de `topics` y la `application_description` se pueden generar instrucciones de mucho tipos y dominios, sé creativ@!"
      ],
      "metadata": {
        "id": "YwQv0l7rqaVZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "topics = [\n",
        "  \"Matemáticas\",\n",
        "  \"Física\",\n",
        "  \"Química\",\n",
        "  \"Biología\",\n",
        "  \"Informática\",\n",
        "  \"Ingeniería\",\n",
        "  \"Astronomía\",\n",
        "  \"Geología\",\n",
        "  \"Ciencias Ambientales\",\n",
        "  \"Robótica\",\n",
        "  \"Estadística\",\n",
        "  \"Ciencias de Materiales\",\n",
        "  \"Nanotecnología\",\n",
        "  \"Genética\",\n",
        "  \"Oceanografía\",\n",
        "  \"Meteorología\",\n",
        "  \"Farmacología\",\n",
        "  \"Neurociencia\",\n",
        "  \"Bioquímica\",\n",
        "  \"Física de Partículas\",\n",
        "  \"Ciencia de Datos\",\n",
        "  \"Inteligencia Artificial\",\n",
        "  \"Sostenibilidad\",\n",
        "  \"Energías Renovables\"\n",
        "]\n",
        "\n",
        "\n",
        "dataset = Dataset.from_dict({\n",
        "    \"input\": topics\n",
        "})"
      ],
      "metadata": {
        "id": "SZMVodOIgxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Te invitamos a probar diferentes prompts y ver cuál da mejores resultados:"
      ],
      "metadata": {
        "id": "gbqntFRazdx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "application_description = (\n",
        "    \"An AI assistant adept at answering a wide array of math, logic, and reasoning puzzles, trivia, \"\n",
        "    \"and general questions. Users of this assistant love to ask the assistant to think and outlines \"\n",
        "    \"the solutions step by step. It expects complete questions from users providing all the details \"\n",
        "    \"to solve the proposed problem or respond to general knowledge questions. It covers general \"\n",
        "    \"knowledge about math, puzzles, reasoning exercises, and real-life scenarios where math and \"\n",
        "    \"reasoning are important. Highly important!! You can only generate text in SPANISH\"\n",
        ")\n",
        "\n",
        "# Por defecto, `SelfInstructTask` generará 5 instrucciones pero se puede modificar este comportamiento con el argumento `num_instructions`.\n",
        "instruction_task = SelfInstructTask(\n",
        "    application_description=application_description\n",
        ")\n",
        "\n",
        "print(f\"`SelfInstructTask`\\n   - Input arguments: {instruction_task.input_args_names}\\n   - Output arguments: {instruction_task.output_args_names}\")"
      ],
      "metadata": {
        "id": "k4ugAnsaibHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf8da02-8e0a-455e-e77f-acce77a47cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`SelfInstructTask`\n",
            "   - Input arguments: ['input']\n",
            "   - Output arguments: ['instructions']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = InferenceEndpointsLLM(\n",
        "    endpoint_name_or_model_id=ENDPOINT_NAME,\n",
        "    task=instruction_task,\n",
        "    token=hf_token,\n",
        "    prompt_format=\"llama2\",\n",
        "    num_threads=4\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(generator=llm)\n",
        "distiset = pipeline.generate(\n",
        "    dataset=dataset,\n",
        "    num_generations=5,\n",
        "    batch_size=4,\n",
        "    display_progress_bar=True\n",
        ")"
      ],
      "metadata": {
        "id": "OQ8-q4LtislP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distiset.to_pandas().head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "jK9LDzuCtFH7",
        "outputId": "6b89bd23-faa6-410b-b88e-c1ce048e3dc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         input                                   generation_model  \\\n",
              "0  Matemáticas  [mistralai/Mixtral-8x7B-Instruct-v0.1, mistral...   \n",
              "1       Física  [mistralai/Mixtral-8x7B-Instruct-v0.1, mistral...   \n",
              "\n",
              "                                   generation_prompt  \\\n",
              "0  [<s>[INST] <<SYS>>\\nYou are an expert prompt w...   \n",
              "1  [<s>[INST] <<SYS>>\\nYou are an expert prompt w...   \n",
              "\n",
              "                            raw_generation_responses  \\\n",
              "0  [ 1. \"Explica detalladamente cómo calcular la ...   \n",
              "1  [ 1. \"Explica paso a paso cómo funciona la seg...   \n",
              "\n",
              "                                        instructions  \n",
              "0  [[\"Explica detalladamente cómo calcular la raí...  \n",
              "1  [[\"Explica paso a paso cómo funciona la segund...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c8fa6c2-db4b-4dee-aa5e-170bad7a4d34\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>generation_model</th>\n",
              "      <th>generation_prompt</th>\n",
              "      <th>raw_generation_responses</th>\n",
              "      <th>instructions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Matemáticas</td>\n",
              "      <td>[mistralai/Mixtral-8x7B-Instruct-v0.1, mistral...</td>\n",
              "      <td>[&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert prompt w...</td>\n",
              "      <td>[ 1. \"Explica detalladamente cómo calcular la ...</td>\n",
              "      <td>[[\"Explica detalladamente cómo calcular la raí...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Física</td>\n",
              "      <td>[mistralai/Mixtral-8x7B-Instruct-v0.1, mistral...</td>\n",
              "      <td>[&lt;s&gt;[INST] &lt;&lt;SYS&gt;&gt;\\nYou are an expert prompt w...</td>\n",
              "      <td>[ 1. \"Explica paso a paso cómo funciona la seg...</td>\n",
              "      <td>[[\"Explica paso a paso cómo funciona la segund...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c8fa6c2-db4b-4dee-aa5e-170bad7a4d34')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c8fa6c2-db4b-4dee-aa5e-170bad7a4d34 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c8fa6c2-db4b-4dee-aa5e-170bad7a4d34');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-efeae3b3-0bad-4a74-8bf6-ee48a3c43d68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-efeae3b3-0bad-4a74-8bf6-ee48a3c43d68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-efeae3b3-0bad-4a74-8bf6-ee48a3c43d68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"distiset\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"F\\u00edsica\",\n          \"Matem\\u00e1ticas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generation_model\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generation_prompt\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"raw_generation_responses\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instructions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspeccionar el dataset en argilla\n",
        "\n",
        "A continuación vamos a crear un espacio en argilla para poder inspeccionar las instrucciones generadas en nuestra pipeline. Podemos crear una instancia de argilla como un espacio de HuggingFace. A continuación se ofrece un ejemplo para hacerlo utilizando la librería de `huggingface_hub`."
      ],
      "metadata": {
        "id": "lN6xA_xUPQE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rg_distiset = distiset.to_argilla(vector_strategy=False, metric_strategy=False)"
      ],
      "metadata": {
        "id": "oYxJzfM8J1gJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import duplicate_space\n",
        "\n",
        "# Crea un HF Space de argilla programáticamente\n",
        "from_id = \"argilla/argilla-template-space\"\n",
        "# Recuerda actualizar esta variable con el nombre del dataset\n",
        "dataset_name = \"mi-dataset\"\n",
        "to_id = f\"{dataset_name}-distiset\"\n",
        "new_space = duplicate_space(from_id, to_id=to_id)\n",
        "new_space"
      ],
      "metadata": {
        "id": "3p8R57j_MYLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto puede llevar unos minutos, puedes visitar el espacio accediendo a `new_space.url`. Una vez que esté listo, el usuario para acceder y contraseña son los que vienen por defecto\n",
        "\n",
        "- usuario: `argilla`\n",
        "- contraseña: `12345678`"
      ],
      "metadata": {
        "id": "NwKsoncNNN6V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación nos conectamos a nuestra instancia para poder subir el dataset:"
      ],
      "metadata": {
        "id": "oAhqCd8ONwpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argilla as rg\n",
        "\n",
        "argilla_api_key = \"admin.apikey\"\n",
        "argilla_space_url = f\"https://{new_space.namespace}-{to_id}.hf.space\"\n",
        "\n",
        "workspace = \"admin\"\n",
        "\n",
        "rg.init(\n",
        "    api_key=argilla_api_key,\n",
        "    api_url=argilla_space_url,\n",
        "    workspace=workspace\n",
        ")"
      ],
      "metadata": {
        "id": "vUC9x_6TN42N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y estamos listos para subir nuestro dataset con las instrucciones para revisarlas antes de avanzar al siguiente paso. Para ello transformamos nuestro dataset al formato necesario de argilla utilizando `to_argilla`, y subimos el dataset a la instancia de argilla utilizando `push_to_argilla`."
      ],
      "metadata": {
        "id": "i6kMlgbBOvvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rg_distiset = distiset.to_argilla(vector_strategy=False, metric_strategy=False)"
      ],
      "metadata": {
        "id": "PgEDtg3-QBba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rg_distiset.push_to_argilla(name=\"instrucciones-distiset\", workspace=workspace)"
      ],
      "metadata": {
        "id": "P_SEu8GPOYCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformar a un dataset para generación de respuestas\n",
        "\n",
        "A continuación vamos a transformar nuestro dataset con instrucciones al formato esperado por `distilabel` para la generación, extrayendo todas las instrucciones anidadas, y poniendo la columna \"input\"."
      ],
      "metadata": {
        "id": "KZHm-_XIQZqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "from datasets import Dataset\n",
        "\n",
        "generations = []\n",
        "for row in distiset:\n",
        "    for instructions in row[\"instructions\"]:\n",
        "        for generation in instructions:\n",
        "            generations.append(generation)\n",
        "\n",
        "generation_dataset = Dataset.from_dict({\"input\": generations})"
      ],
      "metadata": {
        "id": "eWTS5xvUQjdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_dataset"
      ],
      "metadata": {
        "id": "-qy6v5HZRzHx",
        "outputId": "749ee2f1-acbe-44bf-d0d4-35ad392e5b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input'],\n",
              "    num_rows: 14\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generación de respuestas con HF Inference endpoints\n",
        "\n",
        "En esta sección vamos a utilizar el dataset previo `generation_dataset` para generar conjuntos de instrucciones y problemas sintéticos para poder poder ajustar nuestro propio modelo utilizando Supervised Fine Tuning (SFT):"
      ],
      "metadata": {
        "id": "AjDTjpmSsxte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a crear una tarea genérica para generación de texto, reutilizando la misma descripción que pasamos a nuestra tarea previa a modo de *system_prompt*, para guiar al modelo:"
      ],
      "metadata": {
        "id": "Q-DLvtByUfpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_generation_task = TextGenerationTask(system_prompt=application_description)\n",
        "text_generation_task"
      ],
      "metadata": {
        "id": "4mwFUBpvS_EH",
        "outputId": "1de97222-02fb-4645-bfe7-95945d1fa65b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextGenerationTask(system_prompt='An AI assistant adept at answering a wide array of math, logic, and reasoning puzzles, trivia, and general questions. Users of this assistant love to ask the assistant to think and outlines the solutions step by step. It expects complete questions from users providing all the details to solve the proposed problem or respond to general knowledge questions. It covers general knowledge about math, puzzles, reasoning exercises, and real-life scenarios where math and reasoning are important. Highly important!! You can only generate text in SPANISH', principles_distribution=None)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La forma de llamar a nuestra `pipeline` va a ser muy similar en este caso, tendremos una nueva `Task`, y dado que los problemas pueden requerir mayor cantidad de texto, vamos a modificar `max_new_tokens` a 1024."
      ],
      "metadata": {
        "id": "VVWn-XgOYIye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = InferenceEndpointsLLM(\n",
        "    endpoint_name_or_model_id=ENDPOINT_NAME,\n",
        "    task=text_generation_task,\n",
        "    token=hf_token,\n",
        "    prompt_format=\"llama2\",\n",
        "    max_new_tokens=1024,\n",
        "    num_threads=4\n",
        ")\n",
        "\n",
        "pipeline = Pipeline(generator=llm)\n",
        "distiset_generations = pipeline.generate(\n",
        "    dataset=generation_dataset,\n",
        "    num_generations=1,\n",
        "    batch_size=8,\n",
        ")"
      ],
      "metadata": {
        "id": "m6KHFPtqSnGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Igual que hicimos con nuestras instrucciones, vamos a subir ahora nuestro dataset junto con las respuestas generadas para ver lo que ha generado nuestro modelo."
      ],
      "metadata": {
        "id": "UDnGb_B6XZeu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rg_distiset_generations = distiset_generations.to_argilla(vector_strategy=False, metric_strategy=False)"
      ],
      "metadata": {
        "id": "mwzJnwSiWSej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rg_distiset_generations.push_to_argilla(name=\"sciency-distiset\", workspace=workspace)"
      ],
      "metadata": {
        "id": "-9GPSj1SWf7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Push al hub\n",
        "\n",
        "Una vez esté el dataset listo, súbelo a la organización de [SomosNLP](https://huggingface.co/organizations/somosnlp/share/qgytUhPKvxVxsbZWTzVUAUSUnZmVXNPmjc) del hub de Hugging Face. ¡Este paso es imprescindible para participar en el hackathon!"
      ],
      "metadata": {
        "id": "Br5U9PjNg4Ua"
      }
    }
  ]
}